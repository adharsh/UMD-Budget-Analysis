{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salaries over Time from 2013 - 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://salaryguide.dbknews.com/#/salGuide\n",
    "\n",
    "This URL contains a database of all the salaries of all faculty at UMD from 2013 to 2019. At first, we were going to scrape this data from it's web pages, but after talking to the staff who work on \"The Diamondback\", we learned that there is an API endpoint at `https://api.dbknews.com/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is updated as of 2019. If you would like to query data beyond 2019 (or potentially before 2013), you can modify the parameters shown directly below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2013\n",
    "end_year = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there's thouands of faculty and therefore thousands of data points in a single year, all the data cannot be queried at once. Each query will give 10 faculty salaries and this is looped for all the salaries in the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearQueries = list(map(str, range(start_year, end_year + 1)))\n",
    "\n",
    "json_responses = {}\n",
    "years = list(range(start_year, end_year + 1))\n",
    "for yr in years:\n",
    "    json_responses[str(yr)] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in yearQueries: \n",
    "    response = session.get('https://api.dbknews.com/salary/year/' + query)\n",
    "    \n",
    "    data_raw = json.loads(response.content)\n",
    "    for i in range(0, int(data_raw[\"count\"] / 10 + 2)):\n",
    "        response = session.get('https://api.dbknews.com/salary/year/'+ query + '/?page=' + str(i))\n",
    "        if response.status_code == 200:\n",
    "            data = json.loads(response.content)\n",
    "            json_responses[query].append(data)\n",
    "        else:\n",
    "            print('Error ->\\tYear: ', query, \"\\tPage #: \", i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pickle.dump(json_responses, open('json_responses.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "json_responses = pickle.load(open(\"json_responses.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is then merged together and concatted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put dictionary array values into main dictinoary\n",
    "\n",
    "years = sorted(list(map(int, list(json_responses.keys()))))\n",
    "salary_dfs = {}\n",
    "for yr in years:\n",
    "    salary_dfs[str(yr)] = []\n",
    "\n",
    "for year in json_responses.keys():\n",
    "    for page in json_responses[year]:\n",
    "        if year in salary_dfs:\n",
    "            salary_dfs[year].extend(page['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary array values into dataframes and concat dataframes\n",
    "\n",
    "for key in salary_dfs.keys():\n",
    "    salary_dfs[key] = pd.DataFrame(salary_dfs[key])\n",
    "    salary_dfs[key]['Year'] = key\n",
    "salaries = pd.concat(salary_dfs.values(), sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then dropped any duplicates and type casted the columns into the correct types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = salaries.drop_duplicates()\n",
    "salaries = salaries.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries['Year'] = salaries['Year'].astype(int)\n",
    "salaries['Salary'] = salaries['Salary'].replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries['School'] = salaries['Department'].apply(lambda x : x.partition('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = salaries[['Year', 'School', 'Department', 'Division', 'Title', 'Employee', 'Salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.to_pickle('df/salaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries1.loc[(salaries1['Employee'] == 'Varshney, Amitabh') & (salaries1['Year'] == 2019)].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries2.loc[(salaries2['Employee'] == 'Varshney, Amitabh')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
